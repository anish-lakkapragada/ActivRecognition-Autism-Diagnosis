{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first step is preprocessing. We use the [SSBD Dataset](https://rolandgoecke.net/research/datasets/ssbd/) in order to get the data for hand flapping and spinning. \n",
    "\n",
    "## The dataset does contain 75 URLs (although we'll ignore all headbanging videos) to youtube videos. All the data is nicely stored in XML files that I will read to get the youtube videos and also the time stamps of when the behavior (hand flapping or spinning) occurs. Then I will use pytube to download the youtube videos to .mp4 and moviepy to cut the .mp4 videos into the areas of interest. Finally, because some of those areas of interest clips are more than a few seconds long (which is all you need to detect spinning or headbanging) I will take those areas that are > 8 seconds and split them into many clips (that way we have more data.) Also in sections of the video where no behavior is used I will take them as videos as control data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first change the directory over to ssbd release\n",
    "import os \n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.youtube.com/watch?v=T9rbit_oiJA\n",
      "0004:0010\n",
      "armflapping\n",
      "high\n",
      "0015:0020\n",
      "armflapping\n",
      "high\n"
     ]
    }
   ],
   "source": [
    "# next step would be to get the hand flapping and spinning data \n",
    "\n",
    "tree = ET.parse(\"ssbd-release/Annotations/v_ArmFlapping_07.xml\")\n",
    "root = tree.getroot()\n",
    "for child in root:\n",
    "    # for each child in the root \n",
    "    if child.tag == \"url\":\n",
    "        print(child.text)\n",
    "    if child.tag == \"behaviours\":\n",
    "        for behavior in child: # go through each reported behavior \n",
    "            for tag in behavior: # tag is just the attribute of the behavior \n",
    "                if tag.tag == \"time\":\n",
    "                    print(tag.text)\n",
    "                if tag.tag == \"intensity\":\n",
    "                    print(tag.text)\n",
    "                if tag.tag == \"category\":\n",
    "                    print(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_second(time : str) -> int:\n",
    "    # this will take in a time like \"0125\" or 1:25 and make it 85 (60 + 25)\n",
    "    overall_seconds = 0 \n",
    "    for i, time_char in enumerate(reversed(time)):\n",
    "        if i == 0:\n",
    "            overall_seconds += int(time_char)\n",
    "        if i == 1:\n",
    "            overall_seconds += int(time_char) * 10\n",
    "        if i == 2:\n",
    "            overall_seconds += int(time_char) * 60 \n",
    "        if i == 3:\n",
    "            overall_seconds += int(time_char) * 600 \n",
    "    return overall_seconds \n",
    "\n",
    "assert convert_to_second('2345') == 23 * 60 + 45  \n",
    "\n",
    "def consecutive(data, stepsize=1):\n",
    "    '''groups up elements in an array that are continous with each other (useful to create sections where none \n",
    "    of the behaviors are shown.)'''\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math \n",
    "import numpy as np\n",
    "\n",
    "NUM_SECONDS_TO_RECOGNIZE = 8 # hypothesis: takes this many seconds seconds to recognize handflapping + spinning \n",
    "\n",
    "URLS_TO_DOWNLOAD = set() # contains all youtube videos to download \n",
    "links_to_times = {} # data will be stored here like {link : {'category' : [(start, end)], 'another cat' : [(start, end)]}\n",
    "\n",
    "\n",
    "for i, file_name in enumerate(os.listdir('ssbd-release/Annotations/')):\n",
    "    # parse this file \n",
    "    tree = ET.parse('ssbd-release/Annotations/' + file_name)\n",
    "    root = tree.getroot() \n",
    "    \n",
    "    # everything we need to store\n",
    "    URL = \"\"\n",
    "    \n",
    "    for child in root:\n",
    "        \n",
    "        if child.tag == \"url\":\n",
    "            URL = child.text # store URL\n",
    "            URLS_TO_DOWNLOAD.add(URL)\n",
    "            links_to_times[URL] = defaultdict(list) \n",
    "        \n",
    "        if child.tag == \"duration\":\n",
    "            duration = int(child.text[:-1])\n",
    "            all_times = list(range(duration))\n",
    "        \n",
    "        if child.tag == \"behaviours\": # this child has the list of behaviors \n",
    "            for reported_behavior in child: \n",
    "                for info in reported_behavior:\n",
    "                    # gather the start time, end time, and category for this youtube link \n",
    "                    if info.tag == \"time\":\n",
    "                        # the time will be start:end \n",
    "                        times = str(info.text) # contains the string \n",
    "                        if times.count(\":\"): \n",
    "                            divider_index = times.index(\":\")\n",
    "                        elif times.count(\"-\"):\n",
    "                            divider_index = times.index(\"-\")\n",
    "                        else:\n",
    "                            break # invalid then \n",
    "                        actual_start_time, actual_end_time = convert_to_second(times[:divider_index]), convert_to_second(times[divider_index + 1:])\n",
    "                        START_TIMES, END_TIMES = [], []\n",
    "                        times = np.array(range(actual_start_time, actual_end_time +1))\n",
    "                        for time in times:\n",
    "                            try:\n",
    "                                all_times.remove(time)\n",
    "                            except Exception as e:\n",
    "                                pass \n",
    "                        split_times = np.array_split(times, math.ceil(times.shape[0] / NUM_SECONDS_TO_RECOGNIZE))\n",
    "                        for time in split_times:\n",
    "                            START_TIMES.append(time[0])\n",
    "                            END_TIMES.append(time[-1])\n",
    "                    if info.tag == \"category\":\n",
    "                        # this is the label \n",
    "                        LABEL = info.text \n",
    "                \n",
    "                # create an entry for this reported behavior \n",
    "                for START_TIME, END_TIME in zip(START_TIMES, END_TIMES):\n",
    "                    links_to_times[URL][LABEL].append((START_TIME, END_TIME))\n",
    "                    \n",
    "            idle_times = consecutive(np.array(all_times))\n",
    "            num_contributed = 0 # each video can only give 4 control clips (because otherwise it takes WAY too long)\n",
    "            for control_times in idle_times:\n",
    "                if num_contributed >= 4: \n",
    "                    break \n",
    "                # times maybe > NUM_SECONDS_TO_RECOGNIZE so split if that is the case \n",
    "                if len(control_times) <= NUM_SECONDS_TO_RECOGNIZE:\n",
    "                    START_TIME, END_TIME = control_times[0], control_times[-1]\n",
    "                    links_to_times[URL]['control'].append((START_TIME, END_TIME))\n",
    "                    num_contributed += 1\n",
    "                else:\n",
    "                    # needs to be split \n",
    "                    control_times_split = np.array_split(control_times, math.ceil(len(control_times) / NUM_SECONDS_TO_RECOGNIZE))\n",
    "                    for control_time in control_times_split:  \n",
    "                        START_TIME, END_TIME = control_time[0], control_time[-1]\n",
    "                        links_to_times[URL]['control'].append((START_TIME, END_TIME))\n",
    "                        num_contributed += 1\n",
    "                        if num_contributed >= 4: \n",
    "                            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://www.youtube.com/watch?v=Pqd9Vu-juPI': defaultdict(list,\n",
       "             {'spinning': [(10, 15)],\n",
       "              'control': [(0, 4), (5, 9), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=yMgx2lVjf5I': defaultdict(list,\n",
       "             {'headbanging': [(1, 7), (18, 25), (36, 43), (44, 50)],\n",
       "              'control': [(0, 0), (8, 12), (13, 17), (26, 30)]}),\n",
       " 'http://www.youtube.com/watch?v=WRGUUOZ5_wA': defaultdict(list,\n",
       "             {'armflapping': [(60, 67), (60, 67)],\n",
       "              'control': [(0, 7), (8, 15), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=8vFUIFEfRpA': defaultdict(list,\n",
       "             {'armflapping': [(2, 8), (9, 14)],\n",
       "              'control': [(0, 1), (15, 21), (22, 28), (29, 34)]}),\n",
       " 'http://www.youtube.com/watch?v=SOc13pnf-Dc': defaultdict(list,\n",
       "             {'armflapping': [(65, 71),\n",
       "               (72, 78),\n",
       "               (79, 85),\n",
       "               (132, 136),\n",
       "               (137, 140)],\n",
       "              'control': [(0, 7), (8, 15), (16, 22), (23, 29)]}),\n",
       " 'http://www.youtube.com/watch?v=iDuAugAykcc': defaultdict(list,\n",
       "             {'armflapping': [(18, 22),\n",
       "               (23, 27),\n",
       "               (33, 37),\n",
       "               (50, 57),\n",
       "               (68, 73),\n",
       "               (74, 79),\n",
       "               (80, 85)],\n",
       "              'control': [(0, 5), (6, 11), (12, 17), (28, 32)]}),\n",
       " 'http://www.youtube.com/watch?v=BUAFdqrw4fA': defaultdict(list,\n",
       "             {'headbanging': [(8, 13),\n",
       "               (14, 18),\n",
       "               (20, 26),\n",
       "               (27, 32),\n",
       "               (33, 38),\n",
       "               (39, 44),\n",
       "               (54, 61),\n",
       "               (62, 69),\n",
       "               (70, 76),\n",
       "               (77, 83)],\n",
       "              'control': [(0, 7), (19, 19), (45, 49), (50, 53)]}),\n",
       " 'http://www.youtube.com/watch?v=WcsZ9eMQ5Zs': defaultdict(list,\n",
       "             {'headbanging': [(2, 6), (7, 10)],\n",
       "              'control': [(0, 1), (11, 13)]}),\n",
       " 'http://www.youtube.com/watch?v=w96PxUcoo58': defaultdict(list,\n",
       "             {'headbanging': [(5, 10)], 'control': [(0, 4), (11, 13)]}),\n",
       " 'http://www.youtube.com/watch?v=ehlLfMossUY': defaultdict(list,\n",
       "             {'armflapping': [(27, 30), (40, 43), (100, 102)],\n",
       "              'control': [(0, 6), (7, 13), (14, 20), (21, 26)]}),\n",
       " 'http://www.youtube.com/watch?v=mnBWOI4LuKw': defaultdict(list,\n",
       "             {'armflapping': [(3, 9),\n",
       "               (10, 16),\n",
       "               (17, 23),\n",
       "               (24, 30),\n",
       "               (74, 81),\n",
       "               (82, 88),\n",
       "               (89, 95),\n",
       "               (96, 102),\n",
       "               (103, 109),\n",
       "               (110, 116),\n",
       "               (117, 123),\n",
       "               (124, 130),\n",
       "               (134, 141),\n",
       "               (142, 148),\n",
       "               (149, 155)],\n",
       "              'control': [(0, 2), (31, 38), (39, 45), (46, 52)]}),\n",
       " 'http://www.youtube.com/watch?v=3Oh_Lmehb6c': defaultdict(list,\n",
       "             {'armflapping': [(19, 22), (40, 45), (46, 51)],\n",
       "              'control': [(0, 6), (7, 12), (13, 18), (23, 28)]}),\n",
       " 'http://www.youtube.com/watch?v=T9rbit_oiJA': defaultdict(list,\n",
       "             {'armflapping': [(4, 10), (15, 20)],\n",
       "              'control': [(0, 3), (11, 14), (21, 27), (28, 33)]}),\n",
       " 'http://www.youtube.com/watch?v=6sR-8llWl_s': defaultdict(list,\n",
       "             {'headbanging': [(9, 14), (15, 20), (21, 26)],\n",
       "              'control': [(0, 4), (5, 8), (27, 33), (34, 40)]}),\n",
       " 'http://www.youtube.com/watch?v=Z2kfvB4lv7A': defaultdict(list,\n",
       "             {'armflapping': [(22, 27)],\n",
       "              'control': [(0, 7), (8, 14), (15, 21), (28, 34)]}),\n",
       " 'http://www.youtube.com/watch?v=vtVnrV_jog0': defaultdict(list,\n",
       "             {'armflapping': [(2, 8), (9, 14), (19, 23), (36, 39)],\n",
       "              'control': [(0, 1), (15, 18), (24, 29), (30, 35)]}),\n",
       " 'http://www.youtube.com/watch?v=5sgfS0SSh8o': defaultdict(list,\n",
       "             {'armflapping': [(32, 39), (40, 46)], 'control': [(0, 4)]}),\n",
       " 'http://www.youtube.com/watch?v=hKf-IwHM6TI': defaultdict(list,\n",
       "             {'armflapping': [(11, 16), (19, 23), (29, 33)],\n",
       "              'control': [(0, 5), (6, 10), (17, 18), (24, 28)]}),\n",
       " 'http://www.youtube.com/watch?v=zuoD4tEtYyk': defaultdict(list,\n",
       "             {'headbanging': [(1, 7), (8, 14), (15, 20)],\n",
       "              'control': [(0, 0), (21, 21)]}),\n",
       " 'http://www.youtube.com/watch?v=I38WtUMuQwM': defaultdict(list,\n",
       "             {'headbanging': [(30, 35), (36, 40)],\n",
       "              'armflapping': [(124, 130),\n",
       "               (131, 137),\n",
       "               (138, 144),\n",
       "               (145, 150),\n",
       "               (176, 181),\n",
       "               (182, 187),\n",
       "               (206, 211)],\n",
       "              'control': [(0, 7), (8, 15), (16, 22), (23, 29)]}),\n",
       " 'http://www.youtube.com/watch?v=pz1nIbRWb2M': defaultdict(list,\n",
       "             {'armflapping': [(3, 7)],\n",
       "              'control': [(0, 2), (8, 14), (15, 21), (22, 28)]}),\n",
       " 'http://www.youtube.com/watch?v=I7fdv1q9-m8': defaultdict(list,\n",
       "             {'armflapping': [(18, 24)],\n",
       "              'headbanging': [(27, 32)],\n",
       "              'control': [(0, 5), (6, 11), (12, 17), (25, 26)]}),\n",
       " 'http://www.youtube.com/watch?v=nGoMpqcYcOg': defaultdict(list,\n",
       "             {'armflapping': [(17, 23), (32, 37)],\n",
       "              'control': [(0, 5), (6, 11), (12, 16), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=TVMWW9SejgI': defaultdict(list,\n",
       "             {'headbanging': [(1, 8), (9, 15)],\n",
       "              'control': [(0, 0), (16, 20), (21, 25)]}),\n",
       " 'http://www.youtube.com/watch?v=hX3sIO2wc1s': defaultdict(list,\n",
       "             {'headbanging': [(3, 10)], 'control': [(0, 2), (11, 15)]}),\n",
       " 'http://www.youtube.com/watch?v=VxK45NHvHTg': defaultdict(list,\n",
       "             {'spinning': [(25, 28)],\n",
       "              'control': [(0, 6), (7, 12), (13, 18), (19, 24)]}),\n",
       " 'http://www.youtube.com/watch?v=AXghcX_Bjac': defaultdict(list,\n",
       "             {'spinning': [(56, 63)],\n",
       "              'control': [(0, 7), (8, 15), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=scM9g0LExJA': defaultdict(list,\n",
       "             {'spinning': [(1, 8),\n",
       "               (9, 16),\n",
       "               (17, 24),\n",
       "               (25, 32),\n",
       "               (33, 40),\n",
       "               (41, 47),\n",
       "               (60, 67),\n",
       "               (68, 74),\n",
       "               (75, 81),\n",
       "               (82, 88),\n",
       "               (105, 112),\n",
       "               (113, 120),\n",
       "               (121, 128),\n",
       "               (140, 147),\n",
       "               (163, 170),\n",
       "               (171, 178),\n",
       "               (179, 186),\n",
       "               (187, 194),\n",
       "               (195, 202),\n",
       "               (203, 210),\n",
       "               (211, 218),\n",
       "               (219, 226),\n",
       "               (227, 234),\n",
       "               (235, 242),\n",
       "               (243, 250),\n",
       "               (251, 258),\n",
       "               (259, 266),\n",
       "               (267, 274),\n",
       "               (275, 281),\n",
       "               (282, 288),\n",
       "               (289, 295)],\n",
       "              'control': [(0, 0)]}),\n",
       " 'http://www.youtube.com/watch?v=-rC-ab0nzxY': defaultdict(list,\n",
       "             {'spinning': [(26, 31), (32, 37), (38, 43)],\n",
       "              'control': [(0, 6), (7, 13), (14, 19), (20, 25)]}),\n",
       " 'http://www.youtube.com/watch?v=yiEo7Kg1ngY': defaultdict(list,\n",
       "             {'spinning': [(1, 8),\n",
       "               (9, 16),\n",
       "               (17, 24),\n",
       "               (25, 32),\n",
       "               (33, 40),\n",
       "               (41, 48),\n",
       "               (49, 56),\n",
       "               (57, 64),\n",
       "               (65, 72),\n",
       "               (73, 80),\n",
       "               (81, 88),\n",
       "               (89, 96),\n",
       "               (97, 104),\n",
       "               (105, 112),\n",
       "               (113, 120),\n",
       "               (121, 127),\n",
       "               (128, 134),\n",
       "               (135, 141),\n",
       "               (142, 148),\n",
       "               (149, 155)],\n",
       "              'control': [(0, 0), (156, 157)]}),\n",
       " 'http://www.youtube.com/watch?v=8R1MfXoI3mo': defaultdict(list,\n",
       "             {'spinning': [(2, 7),\n",
       "               (15, 22),\n",
       "               (23, 30),\n",
       "               (31, 38),\n",
       "               (39, 45),\n",
       "               (46, 52),\n",
       "               (53, 59),\n",
       "               (60, 66),\n",
       "               (67, 73),\n",
       "               (74, 80)],\n",
       "              'control': [(0, 1), (8, 14)]}),\n",
       " 'http://www.youtube.com/watch?v=5MS6VZwZDi0': defaultdict(list,\n",
       "             {'spinning': [(2, 9),\n",
       "               (10, 17),\n",
       "               (18, 24),\n",
       "               (25, 31),\n",
       "               (32, 38),\n",
       "               (39, 45),\n",
       "               (46, 52),\n",
       "               (53, 59)],\n",
       "              'control': [(0, 1), (60, 66), (67, 73), (74, 80)]}),\n",
       " 'http://www.youtube.com/watch?v=TH5mlAhdw00': defaultdict(list,\n",
       "             {'spinning': [(2, 9)],\n",
       "              'control': [(0, 1), (10, 17), (18, 25), (26, 33)]}),\n",
       " 'http://www.youtube.com/watch?v=kFuxwAufWvQ': defaultdict(list,\n",
       "             {'spinning': [(2, 9),\n",
       "               (10, 17),\n",
       "               (18, 25),\n",
       "               (26, 33),\n",
       "               (34, 40),\n",
       "               (41, 47)],\n",
       "              'control': [(0, 1), (48, 55), (56, 63), (64, 71)]}),\n",
       " 'http://www.youtube.com/watch?v=oukupxRUA84': defaultdict(list,\n",
       "             {'spinning': [(4, 8),\n",
       "               (9, 12),\n",
       "               (28, 34),\n",
       "               (35, 41),\n",
       "               (42, 47),\n",
       "               (58, 64)],\n",
       "              'control': [(0, 3), (13, 20), (21, 27), (48, 52)]}),\n",
       " 'http://www.youtube.com/watch?v=Gt-WMpTP7IE': defaultdict(list,\n",
       "             {'spinning': [(1, 8),\n",
       "               (9, 16),\n",
       "               (17, 24),\n",
       "               (25, 32),\n",
       "               (33, 40),\n",
       "               (41, 48),\n",
       "               (49, 56),\n",
       "               (57, 63),\n",
       "               (64, 70)],\n",
       "              'control': [(0, 0), (71, 78), (79, 85)]}),\n",
       " 'http://www.youtube.com/watch?v=uWgI1w2fQhs': defaultdict(list,\n",
       "             {'spinning': [(3, 9), (10, 16), (17, 22), (23, 28)],\n",
       "              'control': [(0, 2), (29, 35), (36, 42)]}),\n",
       " 'http://www.youtube.com/watch?v=VAMZwnfAHyY': defaultdict(list,\n",
       "             {'spinning': [(3, 8), (9, 14), (15, 20)],\n",
       "              'control': [(0, 2), (21, 27), (28, 33)]}),\n",
       " 'http://www.youtube.com/watch?v=arn5UCMLlBo': defaultdict(list,\n",
       "             {'spinning': [(2, 8), (9, 15)], 'control': [(0, 1), (16, 18)]}),\n",
       " 'http://www.youtube.com/watch?v=5BVFjqo0FUY': defaultdict(list,\n",
       "             {'spinning': [(1, 8),\n",
       "               (9, 16),\n",
       "               (17, 24),\n",
       "               (36, 43),\n",
       "               (44, 51),\n",
       "               (52, 59),\n",
       "               (60, 67),\n",
       "               (68, 75),\n",
       "               (76, 82),\n",
       "               (83, 89),\n",
       "               (90, 96),\n",
       "               (97, 103),\n",
       "               (104, 110),\n",
       "               (111, 117),\n",
       "               (125, 131),\n",
       "               (132, 138),\n",
       "               (139, 145),\n",
       "               (146, 152),\n",
       "               (153, 159),\n",
       "               (160, 165),\n",
       "               (180, 186),\n",
       "               (187, 193),\n",
       "               (194, 199)],\n",
       "              'control': [(0, 0), (25, 30), (31, 35), (118, 124)]}),\n",
       " 'http://www.youtube.com/watch?v=2AS14wxMB-A': defaultdict(list,\n",
       "             {'spinning': [(6, 12), (13, 18)],\n",
       "              'control': [(0, 5), (19, 24), (25, 29)]}),\n",
       " 'http://www.youtube.com/watch?v=cxqsde-6V-c': defaultdict(list,\n",
       "             {'spinning': [(1, 7), (8, 14), (15, 20)],\n",
       "              'control': [(0, 0), (21, 27), (28, 33), (34, 39)]}),\n",
       " 'http://www.youtube.com/watch?v=ZHJr17Q4384': defaultdict(list,\n",
       "             {'spinning': [(2, 9),\n",
       "               (10, 17),\n",
       "               (18, 25),\n",
       "               (26, 33),\n",
       "               (34, 41),\n",
       "               (42, 49),\n",
       "               (50, 57),\n",
       "               (58, 65),\n",
       "               (66, 73),\n",
       "               (74, 81),\n",
       "               (82, 89),\n",
       "               (90, 96),\n",
       "               (97, 103),\n",
       "               (104, 110)],\n",
       "              'control': [(0, 1), (111, 114)]}),\n",
       " 'http://www.youtube.com/watch?v=NDcUGYlTy_4': defaultdict(list,\n",
       "             {'spinning': [(6, 12), (75, 81), (82, 88), (89, 95)],\n",
       "              'control': [(0, 5), (13, 20), (21, 28), (29, 36)]}),\n",
       " 'http://www.youtube.com/watch?v=sAgAvYT3D8s': defaultdict(list,\n",
       "             {'spinning': [(10, 15), (16, 20)],\n",
       "              'control': [(0, 4), (5, 9), (21, 28), (29, 36)]}),\n",
       " 'http://www.youtube.com/watch?v=wu5fgT-LkHs': defaultdict(list,\n",
       "             {'spinning': [(2, 8),\n",
       "               (9, 14),\n",
       "               (15, 20),\n",
       "               (30, 36),\n",
       "               (37, 43),\n",
       "               (44, 50),\n",
       "               (51, 57),\n",
       "               (58, 63)],\n",
       "              'control': [(0, 1), (21, 25), (26, 29), (64, 71)]}),\n",
       " 'http://www.youtube.com/watch?v=uNpUNkjNreg': defaultdict(list,\n",
       "             {'spinning': [(68, 75), (76, 83)],\n",
       "              'control': [(0, 7), (8, 15), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=gKED6S0eGYA': defaultdict(list,\n",
       "             {'spinning': [(1, 5), (6, 10)],\n",
       "              'control': [(0, 0), (11, 18), (19, 25)]}),\n",
       " 'http://www.youtube.com/watch?v=pgj_LKf6jL4': defaultdict(list,\n",
       "             {'spinning': [(51, 58)],\n",
       "              'control': [(0, 7), (8, 15), (16, 22), (23, 29)]}),\n",
       " 'http://www.youtube.com/watch?v=yCaymsrcNwA': defaultdict(list,\n",
       "             {'headbanging': [(1, 4)],\n",
       "              'control': [(0, 0), (5, 11), (12, 18), (19, 24)]}),\n",
       " 'http://www.youtube.com/watch?v=9zOrUA7Kn4o': defaultdict(list,\n",
       "             {'headbanging': [(1, 8), (9, 16), (17, 23)],\n",
       "              'control': [(0, 0), (24, 31), (32, 38), (39, 45)]}),\n",
       " 'http://www.youtube.com/watch?v=AGmXuSY4gx0': defaultdict(list,\n",
       "             {'armflapping': [(8, 15)],\n",
       "              'control': [(0, 7), (16, 22), (23, 28), (29, 34)]}),\n",
       " 'http://www.youtube.com/watch?v=JM8BHjJTSFM': defaultdict(list,\n",
       "             {'armflapping': [(3, 7), (40, 45), (46, 50)],\n",
       "              'control': [(0, 2), (8, 15), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=1vRklwIBC28': defaultdict(list,\n",
       "             {'headbanging': [(60, 66),\n",
       "               (67, 73),\n",
       "               (74, 80),\n",
       "               (81, 87),\n",
       "               (88, 94),\n",
       "               (100, 106),\n",
       "               (107, 113),\n",
       "               (114, 120)],\n",
       "              'armflapping': [(175, 182), (183, 190), (205, 212), (213, 219)],\n",
       "              'control': [(0, 7), (8, 15), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=I2rfPPinMHk': defaultdict(list,\n",
       "             {'armflapping': [(4, 8)],\n",
       "              'control': [(0, 3), (9, 15), (16, 22)]}),\n",
       " 'http://www.youtube.com/watch?v=0Vk9itex_ds': defaultdict(list,\n",
       "             {'headbanging': [(4, 10), (11, 17), (18, 24), (25, 30)],\n",
       "              'control': [(0, 3), (31, 32)]}),\n",
       " 'http://www.youtube.com/watch?v=Lw-MsQ2k6ZQ': defaultdict(list,\n",
       "             {'headbanging': [(10, 17)],\n",
       "              'control': [(0, 4), (5, 9), (18, 25), (26, 32)]}),\n",
       " 'http://www.youtube.com/watch?v=a5BuwkqtIa0': defaultdict(list,\n",
       "             {'headbanging': [(4, 9), (36, 40), (41, 44)],\n",
       "              'control': [(0, 3), (10, 16), (17, 23), (24, 29)]}),\n",
       " 'http://www.youtube.com/watch?v=k9MJ4pDQQ74': defaultdict(list,\n",
       "             {'headbanging': [(6, 10), (11, 14)], 'control': [(0, 5)]}),\n",
       " 'http://www.youtube.com/watch?v=8SrUO-NdSZU': defaultdict(list,\n",
       "             {'headbanging': [(2, 9),\n",
       "               (10, 16),\n",
       "               (17, 23),\n",
       "               (24, 30),\n",
       "               (31, 37),\n",
       "               (38, 44),\n",
       "               (45, 51),\n",
       "               (52, 58)],\n",
       "              'control': [(0, 1), (59, 66), (67, 73), (74, 80)]}),\n",
       " 'http://www.youtube.com/watch?v=B9hYEIjsHDA': defaultdict(list,\n",
       "             {'headbanging': [(2, 8), (9, 14), (15, 20)],\n",
       "              'control': [(0, 1), (21, 25), (26, 29)]}),\n",
       " 'http://www.youtube.com/watch?v=nwLp0k1xa0o': defaultdict(list,\n",
       "             {'headbanging': [(55, 59), (60, 64)],\n",
       "              'control': [(0, 7), (8, 15), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=UxpQpWzhOx0': defaultdict(list,\n",
       "             {'armflapping': [(2, 6),\n",
       "               (41, 48),\n",
       "               (49, 55),\n",
       "               (60, 67),\n",
       "               (68, 75),\n",
       "               (76, 82),\n",
       "               (83, 89),\n",
       "               (94, 98),\n",
       "               (99, 102),\n",
       "               (110, 114),\n",
       "               (115, 118)],\n",
       "              'control': [(0, 1), (7, 13), (14, 20), (21, 27)]}),\n",
       " 'http://www.youtube.com/watch?v=xeKKMkVgNPU': defaultdict(list,\n",
       "             {'armflapping': [(3, 9), (60, 65), (66, 70)],\n",
       "              'spinning': [(49, 53), (54, 57)],\n",
       "              'control': [(0, 2), (10, 17), (18, 25), (26, 33)]}),\n",
       " 'http://www.youtube.com/watch?v=WLtorzPESbc': defaultdict(list,\n",
       "             {'headbanging': [(10, 14), (15, 19)],\n",
       "              'control': [(0, 4), (5, 9), (20, 22)]}),\n",
       " 'http://www.youtube.com/watch?v=5WTHMIJ_61I': defaultdict(list,\n",
       "             {'headbanging': [(2, 7), (8, 12)],\n",
       "              'control': [(0, 1), (13, 20), (21, 28), (29, 36)]}),\n",
       " 'http://www.youtube.com/watch?v=pzPhXbGEpSo': defaultdict(list,\n",
       "             {'headbanging': [(16, 23), (24, 30), (34, 39)],\n",
       "              'control': [(0, 7), (8, 15), (31, 33), (40, 46)]}),\n",
       " 'http://www.youtube.com/watch?v=aNaC46cUOJo': defaultdict(list,\n",
       "             {'headbanging': [(16, 22)],\n",
       "              'control': [(0, 7), (8, 15), (23, 30), (31, 38)]}),\n",
       " 'http://www.youtube.com/watch?v=C_O8vyrSt0Q': defaultdict(list,\n",
       "             {'armflapping': [(5, 10),\n",
       "               (11, 15),\n",
       "               (30, 37),\n",
       "               (38, 44),\n",
       "               (55, 62),\n",
       "               (63, 70),\n",
       "               (85, 92),\n",
       "               (93, 100),\n",
       "               (125, 132),\n",
       "               (133, 139)],\n",
       "              'control': [(0, 4), (16, 22), (23, 29), (45, 49)]}),\n",
       " 'http://www.youtube.com/watch?v=AQ-jO6O5gow': defaultdict(list,\n",
       "             {'armflapping': [(7, 11), (12, 16)],\n",
       "              'control': [(0, 6), (17, 22)]}),\n",
       " 'http://www.youtube.com/watch?v=MOt-6FAEP_g': defaultdict(list,\n",
       "             {'armflapping': [(94, 98)],\n",
       "              'control': [(0, 7), (8, 15), (16, 23), (24, 31)]}),\n",
       " 'http://www.youtube.com/watch?v=5Ps9iE8mPqY': defaultdict(list,\n",
       "             {'armflapping': [(18, 21),\n",
       "               (47, 51),\n",
       "               (70, 77),\n",
       "               (90, 96),\n",
       "               (97, 102),\n",
       "               (103, 108),\n",
       "               (122, 128),\n",
       "               (129, 134),\n",
       "               (195, 200),\n",
       "               (218, 223)],\n",
       "              'control': [(0, 5), (6, 11), (12, 17), (22, 28)]}),\n",
       " 'http://www.youtube.com/watch?v=Pa-pdBF4FFA': defaultdict(list,\n",
       "             {'headbanging': [(36, 39)],\n",
       "              'control': [(0, 7), (8, 14), (15, 21), (22, 28)]}),\n",
       " 'http://www.youtube.com/watch?v=Lex0gIMd73g': defaultdict(list,\n",
       "             {'headbanging': [(3, 10), (11, 17)],\n",
       "              'control': [(0, 2), (18, 19)]})}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_to_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle this just incase \n",
    "import pickle \n",
    "with open(\"links_to_times.pkl\", 'wb') as f:\n",
    "    pickle.dump(links_to_times, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import pytube\n",
    "FPS = 30 \n",
    "i = 0 \n",
    "for vid, (url, category_times) in enumerate((links_to_times.items())): \n",
    "    print(f\"staring the {vid+1}th file\")\n",
    "    # download the video \n",
    "    print(url)\n",
    "    try: \n",
    "        print(\"This is url: \", url)\n",
    "        y = pytube.YouTube(url)\n",
    "        video = y.streams.get_highest_resolution()\n",
    "        video.download()\n",
    "    except Exception as e:\n",
    "        print(f\"annoying url: {url}\")\n",
    "        print(e)\n",
    "        continue \n",
    "        \n",
    "    for category, times in category_times.items(): \n",
    "        folder_path = \"behavior_data/\" + category + \"/\"\n",
    "        \n",
    "        for start_time, end_time in times:\n",
    "            try:\n",
    "                input_file = y.streams.get_highest_resolution().default_filename\n",
    "                output_file = folder_path + f\"{i}.mp4\"\n",
    "                print(os.listdir(folder_path))\n",
    "                if f\"{i}.mp4\" not in os.listdir(folder_path):\n",
    "                    print(\"adding file\")\n",
    "                    with VideoFileClip(input_file) as video:\n",
    "                        new = video.subclip(start_time, end_time)\n",
    "                        new.write_videofile(output_file, audio_codec='aac')\n",
    "                        i += 1 \n",
    "            except Exception as e:\n",
    "                print(f\"failed on {i}\")\n",
    "                i += 1 \n",
    "    os.remove(y.streams.get_highest_resolution().default_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory Structure  \n",
    "\n",
    "## We have one folder inside of this AnishMachineLearning folder called \"behavior_data\" that has the \"armflapping\" and \"spinning\" folders. There all of the sliced .mp4 files with the behavior of interest are located. \n",
    "\n",
    "### We will process headbanging videos even if we are not going to use it because we still want it as a negative case for training the arm flapping & spinning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spinning it is just the hand positions that matter right?\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp \n",
    "import numpy as np\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"/Users/anish/Documents/Machine Learning Env/AnishMachineLearning/behavior_data/spinning/37.mp4\")\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "\n",
    "#capcv2.VideoCapture(0)\n",
    "\n",
    "hands = mp_hands.Hands(min_detection_confidence = 0.5, min_tracking_confidence = 0.5)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read() \n",
    "    if not ret:break \n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False \n",
    "    results = hands.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    white_image = np.zeros_like(image)\n",
    "    white_image.fill(255.0)\n",
    "    \n",
    "    #check for hand results \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmark in results.multi_hand_landmarks:\n",
    "            for i in range(0, 21):\n",
    "                landmark = hand_landmark.landmark[i]\n",
    "                x = int(landmark.x * width)\n",
    "                y = int(landmark.y * height)\n",
    "                cv2.circle(white_image, (x, y), 5, (100, 100, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"\", white_image)\n",
    "\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break \n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can try using the y values for each of the hand flapping videos and graph them to see if there is a noticeable difference of the y-values (we'll use the mean of all y-values for all 21 hand landmarks and then graph them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "# first all hand flapping videos \n",
    "for hand_flap_video in os.listdir(\"behavior_data/armflapping\"):\n",
    "    video = \"behavior_data/armflapping/\" + hand_flap_video\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    \n",
    "    hands = mp_hands.Hands(min_detection_confidence = 0.5, min_tracking_confidence = 0.5)\n",
    "    \n",
    "    all_YS = [] \n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read() \n",
    "        if not ret:break \n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False \n",
    "        results = hands.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        #check for hand results \n",
    "        y_s = []\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmark in results.multi_hand_landmarks:\n",
    "                for i in range(0, 21):\n",
    "                    landmark = hand_landmark.landmark[i]\n",
    "                    x = int(landmark.x * width)\n",
    "                    y = int(landmark.y * height)\n",
    "                    y_s.append(y)\n",
    "        \n",
    "        all_YS.append(np.mean(y_s))\n",
    "\n",
    "    plt.plot(range(len(all_YS)), all_YS, color = \"green\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for spinning \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "# first all hand flapping videos \n",
    "for hand_flap_video in os.listdir(\"behavior_data/spinning\"):\n",
    "    video = \"behavior_data/spinning/\" + hand_flap_video\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    \n",
    "    hands = mp_hands.Hands(min_detection_confidence = 0.5, min_tracking_confidence = 0.5)\n",
    "    \n",
    "    all_YS = [] \n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read() \n",
    "        if not ret:break \n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False \n",
    "        results = hands.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        #check for hand results \n",
    "        y_s = []\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmark in results.multi_hand_landmarks:\n",
    "                for i in range(0, 21):\n",
    "                    landmark = hand_landmark.landmark[i]\n",
    "                    x = int(landmark.x * width)\n",
    "                    y = int(landmark.y * height)\n",
    "                    y_s.append(y)\n",
    "        \n",
    "        all_YS.append(np.mean(y_s))\n",
    "\n",
    "    plt.plot(range(len(all_YS)), all_YS, color = \"green\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next for headbanging \n",
    "\n",
    "# now for spinning \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "# first all hand flapping videos \n",
    "for hand_flap_video in os.listdir(\"behavior_data/headbanging\"):\n",
    "    video = \"behavior_data/headbanging/\" + hand_flap_video\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    \n",
    "    hands = mp_hands.Hands(min_detection_confidence = 0.5, min_tracking_confidence = 0.5)\n",
    "    \n",
    "    all_YS = [] \n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read() \n",
    "        if not ret:break \n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False \n",
    "        results = hands.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        #check for hand results \n",
    "        y_s = []\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmark in results.multi_hand_landmarks:\n",
    "                for i in range(0, 21):\n",
    "                    landmark = hand_landmark.landmark[i]\n",
    "                    x = int(landmark.x * width)\n",
    "                    y = int(landmark.y * height)\n",
    "                    y_s.append(y)\n",
    "        \n",
    "        all_YS.append(np.mean(y_s))\n",
    "\n",
    "    plt.plot(range(len(all_YS)), all_YS, color = \"green\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First let's get the frames for every arm flapping and control video. If the number of frames is less than 100 frames we will not take it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "ARMFLAPPING_VIDEOS = []\n",
    "CONTROL_VIDEOS = []\n",
    "\n",
    "for video_name in os.listdir('behavior_data/armflapping'): \n",
    "    cap = cv2.VideoCapture('behavior_data/armflapping/' + video_name)  \n",
    "    FRAMES = [] # frames for this video \n",
    "    while True: \n",
    "        _, image = cap.read() \n",
    "        if not _ : break \n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        FRAMES.append(image)\n",
    "    if len(FRAMES) >= 100: \n",
    "        # ignore any .DS_Store files\n",
    "        ARMFLAPPING_VIDEOS.append(np.array(FRAMES))\n",
    "\n",
    "ARMFLAPPING_LABELS = np.ones(len(ARMFLAPPING_VIDEOS))\n",
    "\n",
    "for video_name in os.listdir('behavior_data/control'): \n",
    "    cap = cv2.VideoCapture('behavior_data/control/' + video_name)  \n",
    "    FRAMES = [] # frames for this video \n",
    "    while True: \n",
    "        _, image = cap.read() \n",
    "        if not _ : break \n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        FRAMES.append(image)\n",
    "        \n",
    "    if len(FRAMES) >= 100: \n",
    "        CONTROL_VIDEOS.append(np.array(FRAMES))\n",
    "\n",
    "CONTROL_LABELS = np.zeros(len(CONTROL_VIDEOS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-19e0f5b4e4ea>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ARMFLAPPING_VIDEOS = np.array(ARMFLAPPING_VIDEOS)\n",
      "<ipython-input-4-19e0f5b4e4ea>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  CONTROL_VIDEOS = np.array(CONTROL_VIDEOS)\n"
     ]
    }
   ],
   "source": [
    "# shuffle and then balance the amount of videos\n",
    "print(len(CONTROL_VIDEOS), len(ARMFLAPPING_VIDEOS))\n",
    "amount_of_videos = min([len(CONTROL_VIDEOS), len(ARMFLAPPING_VIDEOS)])\n",
    "\n",
    "ARMFLAPPING_VIDEOS = np.array(ARMFLAPPING_VIDEOS)\n",
    "CONTROL_VIDEOS = np.array(CONTROL_VIDEOS)\n",
    "import numpy as np\n",
    "control_permutation = np.random.permutation(CONTROL_LABELS.shape[0])\n",
    "CONTROL_VIDEOS, CONTROL_LABELS = CONTROL_VIDEOS[control_permutation], CONTROL_LABELS[control_permutation]\n",
    "\n",
    "armflapping_permutation = np.random.permutation(ARMFLAPPING_LABELS.shape[0])\n",
    "ARMFLAPPING_VIDEOS, ARMFLAPPING_LABELS = ARMFLAPPING_VIDEOS[armflapping_permutation], ARMFLAPPING_LABELS[armflapping_permutation]\n",
    "\n",
    "ARMFLAPPING_VIDEOS, ARMFLAPPING_LABELS = ARMFLAPPING_VIDEOS[:amount_of_videos], ARMFLAPPING_LABELS[:amount_of_videos]\n",
    "CONTROL_VIDEOS, CONTROL_LABELS = CONTROL_VIDEOS[:amount_of_videos], CONTROL_LABELS[:amount_of_videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ARMFLAPPING_VIDEOS) == len(CONTROL_VIDEOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great we have gotten 53 videos of armflapping and 53 control videos. Every single video has a minimum of 100 frames. We have set the predetermined amount of frames that go into the LSTM at 100, because we don't want the model to overfit or care about the length of the video. For videos with more than 100 frames, we will only collect the first 100 frames. \n",
    "\n",
    "## When we get the x and y locations for where on the 21 hand landmarks, note that they will be based on the width / height of the video which varies from each video . One way to deal with this would be to simply make all frames the same width and height, however that may make it tough for mediapipe to actually find the landmarks. Because the average frame has roughly a height and width of 400x600 we will take whatever x and y values given for a frame and adjust them based on the frame's height/width divided by 400 /600. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "armflapping_videos_shapes = [] \n",
    "for video in ARMFLAPPING_VIDEOS: \n",
    "    armflapping_videos_shapes.append(list(np.array(video).shape)) # (frames, height, width, num channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159.13207547, 411.62264151, 581.88679245,   3.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(armflapping_videos_shapes, axis = 0) # average height and width for the armflapping frames is 403 x 562 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_videos_shapes = [] \n",
    "for video in CONTROL_VIDEOS:\n",
    "    control_videos_shapes.append(list(np.array(video).shape)) # (frames, height, width, num channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(control_videos_shapes, axis = 0) # average height and width for the armflapping frames is 419 x 581 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_armflapping_frames = [] # the dimensions of this will be (75, 100, height, width, channels)\n",
    "selected_control_frames = [] \n",
    "\n",
    "for FRAMES in ARMFLAPPING_VIDEOS: \n",
    "    selected_armflapping_frames.append(FRAMES[:100])\n",
    "\n",
    "for FRAMES in CONTROL_VIDEOS: \n",
    "    selected_control_frames.append(FRAMES[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we also will need to do some augmentations on the images itself before making them into the vector representation. Below we'll try using  we'll see what ranges work best on the images in order to make sure mediapipe can actually still locate where the hands are even if the image has been augmented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we are testing to see the right image augmentation values \n",
    "# we'll want to know whether a certain value will allow mediapipe to recognize the images \n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.1, min_tracking_confidence=0.1) # MAKE SURE THIS IS ALL GOOD\n",
    "\n",
    "def mediapipe_image(image): \n",
    "\n",
    "  # Flip on horizontal\n",
    "  image = cv2.flip(image, 1)\n",
    "\n",
    "  # Set flag\n",
    "  image.flags.writeable = False\n",
    "\n",
    "  # Detections\n",
    "  results = hands.process(image)\n",
    "\n",
    "  # Set flag to true\n",
    "  image.flags.writeable = True\n",
    "\n",
    "  # Detections\n",
    "  print(results)\n",
    "\n",
    "  # Rendering results\n",
    "  if results.multi_hand_landmarks:\n",
    "      for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "          mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=5, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=5, circle_radius=2),\n",
    "                                    )\n",
    "  return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidaug import augmentors as va\n",
    "\n",
    "selected_armflapping_frames[0][0].shape\n",
    "\n",
    "seq = va.Sequential([\n",
    "    va.RandomCrop((360, 480))\n",
    "])\n",
    "\n",
    "\n",
    "video_aug = seq(selected_armflapping_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_aug = np.array(video_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create our custom layer for image augmentations. We will be using a transformation of rotation, height and width, and shear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import math \n",
    "import numpy as np\n",
    "import random \n",
    "import tensorflow as tf \n",
    "import tensorflow.python.ops.numpy_ops.np_config as np_config\n",
    "import tensorflow_addons as tfa\n",
    "from vidaug import augmentors as va\n",
    "from joblib import parallel_backend, delayed \n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "class MediapipeAugLayer(keras.layers.Layer): \n",
    "    def __init__(self, height_shift = 0.05, width_shift = 0.05, zoom_range = (0.8, 1.2), rotation_range = 10): \n",
    "        super().__init__()\n",
    "        self.training = True\n",
    "        self.height_shift, self.width_shift = height_shift, width_shift\n",
    "        self.zoom_range = zoom_range\n",
    "        self.rotation_range = rotation_range\n",
    "        \n",
    "    def __call__(self, X): \n",
    "        # X is of size [BS, 100, H?, W?, 3]\n",
    "        # and we need to return [BS, 100, 42]\n",
    "        \n",
    "        if self.training: \n",
    "            out = []\n",
    "            for video_seq in X: \n",
    "                height, width, _ = video_seq[0].shape \n",
    "                dx = random.randrange(- int(width * self.width_shift), int(width * self.width_shift))\n",
    "                dy = random.randrange(- int(height * self.height_shift), int(height * self.height_shift))\n",
    "                \n",
    "                # translate all images \n",
    "                video_seq = tfa.image.translate(video_seq, [dx, dy], fill_mode = \"nearest\")\n",
    "                \n",
    "                # rotate all images \n",
    "                rotation_degree = random.randrange(-self.rotation_range, self.rotation_range)\n",
    "                video_seq = tfa.image.rotate(video_seq, rotation_degree * math.pi / 180)\n",
    "                \n",
    "                if random.random() < 0.5: \n",
    "                    video_seq = tf.image.flip_left_right(video_seq) # 50% of the time, flip the image  \n",
    "                \n",
    "                out.append(video_seq) \n",
    "            return out\n",
    "        else: \n",
    "            return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function translate at 0x7fcb813d5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function translate at 0x7fcb813d5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "layer = MediapipeAugLayer()\n",
    "out = layer(selected_armflapping_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(MediapipeAugLayer())\n",
    "model.add(keras.layers.LSTM(64, return_sequences =True))\n",
    "model.add(keras.layers.LSTM(128, return_sequences =True))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
