{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2114f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code for databricks, to demo the model. \n",
    "\n",
    "(CPU Version tho for the broke bois)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "print(tf.__version__)\n",
    "\n",
    "IMAGE_SIZE = (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8641950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_2():\n",
    "    def build_convnet(shape=None):\n",
    "        momentum = 0.9\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3,3), input_shape=shape[1:], padding='same', activation='linear'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=momentum))\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='linear'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=momentum))\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='linear'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=momentum))\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        # flatten\n",
    "        model.add(tf.keras.layers.GlobalMaxPool2D())\n",
    "        return model\n",
    "    shape = (90, IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_SIZE[2])\n",
    "    print('Train data shape: ', shape)\n",
    "\n",
    "    convnet = build_convnet(shape)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.TimeDistributed(convnet, input_shape=shape))\n",
    "    model.add(tf.keras.layers.LSTM(64))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(.5))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(.5))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(.5))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7a3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(): \n",
    "    inp =  tf.keras.layers.Input((None, IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_SIZE[2])) # , ragged=True\n",
    "    \n",
    "    mobilenet_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        include_top=False, weights='imagenet', pooling='max', classes=2, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "    )\n",
    "    \n",
    "    for k,v in mobilenet_model._get_trainable_state().items():\n",
    "        k.trainable = False\n",
    "    \n",
    "    x = tf.keras.layers.TimeDistributed(mobilenet_model)(inp)\n",
    "    x = tf.keras.layers.LSTM(64, return_sequences=False)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    out = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, out)\n",
    "\n",
    "    model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam(learning_rate=0.01), metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01cdeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../file_names_folds.pkl\", 'rb') as f: \n",
    "    SEEDS, FOLD_FILES = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6765aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:::  {'train': ['_48.mp4', '_61.mp4', '_71.mp4', '_10.mp4', '_17.mp4', '_101.mp4', '_65.mp4', '_66.mp4', '_6.mp4', '_49.mp4', '_63.mp4', '_89.mp4', '_76.mp4', '_14.mp4', '_111.mp4', '_114.mp4', '_99.mp4', '_72.mp4', '_3.mp4', '_106.mp4', '_110.mp4', '_77.mp4', '_115.mp4', '_13.mp4', '_12.mp4', '_5.mp4', '_107.mp4', '_105.mp4', '_11.mp4', '_64.mp4', '_75.mp4', '_74.mp4', '_1.mp4', '_16.mp4', '_100.mp4', '_7.mp4', '_88.mp4', '_60.mp4', '_112.mp4', '_102.mp4', '_166.mp4', '_173.mp4', '_138.mp4', '_144.mp4', '_130.mp4', '_140.mp4', '_163.mp4', '_162.mp4', '_154.mp4', '_172.mp4', '_175.mp4', '_165.mp4', '_164.mp4', '_120.mp4', '_124.mp4', '_142.mp4', '_160.mp4', '_174.mp4', '_153.mp4', '_134.mp4', '_128.mp4', '_159.mp4', '_169.mp4', '_143.mp4', '_157.mp4', '_156.mp4', '_137.mp4', '_118.mp4', '_178.mp4', '_176.mp4', '_167.mp4', '_170.mp4', '_116.mp4', '_119.mp4', '_181.mp4', '_179.mp4', '_171.mp4', '_158.mp4', '_152.mp4', '_186.mp4'], 'test': ['_2.mp4', '_29.mp4', '_98.mp4', '_104.mp4', '_38.mp4', '_39.mp4', '_113.mp4', '_0.mp4', '_4.mp4', '_28.mp4', '_126.mp4', '_122.mp4', '_161.mp4', '_129.mp4', '_151.mp4', '_187.mp4', '_127.mp4', '_132.mp4', '_180.mp4', '_136.mp4']}\n",
      "(80, 90, 224, 224, 3) (20, 90, 224, 224, 3) (80,) (20,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-02 08:01:49.121798: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 124s 22s/step - loss: 0.6838 - accuracy: 0.6875 - precision: 0.8261 - recall: 0.4750 - val_loss: 0.5430 - val_accuracy: 0.7500 - val_precision: 0.7778 - val_recall: 0.7000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 97s 20s/step - loss: 0.6222 - accuracy: 0.6750 - precision: 0.6750 - recall: 0.6750 - val_loss: 0.4832 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 87s 18s/step - loss: 0.5873 - accuracy: 0.7000 - precision: 0.6818 - recall: 0.7500 - val_loss: 0.4571 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 84s 18s/step - loss: 0.5127 - accuracy: 0.7625 - precision: 0.7561 - recall: 0.7750 - val_loss: 0.4458 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 83s 18s/step - loss: 0.5146 - accuracy: 0.7750 - precision: 0.7750 - recall: 0.7750 - val_loss: 0.3956 - val_accuracy: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.4858 - accuracy: 0.7875 - precision: 0.8286 - recall: 0.7250 - val_loss: 0.3981 - val_accuracy: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.4717 - accuracy: 0.8250 - precision: 0.9062 - recall: 0.7250 - val_loss: 0.3965 - val_accuracy: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.4777 - accuracy: 0.7625 - precision: 0.7561 - recall: 0.7750 - val_loss: 0.3961 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 80s 17s/step - loss: 0.4654 - accuracy: 0.8125 - precision: 0.8205 - recall: 0.8000 - val_loss: 0.4152 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 80s 17s/step - loss: 0.4088 - accuracy: 0.8250 - precision: 0.8824 - recall: 0.7500 - val_loss: 0.3902 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "fold = FOLD_FILES[0]\n",
    "\n",
    "print('FOLD::: ', fold)\n",
    "\n",
    "train_files = [a.strip('_') for a in fold['train']]\n",
    "test_files = [a.strip('_') for a in fold['test']]\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for filename in train_files:\n",
    "    filename_int = int(filename.split('.mp4')[0])\n",
    "\n",
    "    if filename_int <= 115:\n",
    "        curr_y = 1\n",
    "        subdir_name = 'armflapping'\n",
    "    else:\n",
    "        curr_y = 0\n",
    "        subdir_name = 'control'\n",
    "\n",
    "    curr_x = []\n",
    "    for frame in os.listdir('../behavior_data/' + subdir_name + '/' + filename):\n",
    "\n",
    "        frame_num = int(frame.split('.')[0])\n",
    "        if frame_num > 90:\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread('../behavior_data/' + subdir_name + '/' + filename + '/' + frame)\n",
    "        try:\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        curr_x.append(image)\n",
    "\n",
    "    len_data = len(os.listdir('../behavior_data/' + subdir_name + '/' + filename))\n",
    "    if len_data < 90:\n",
    "        for abc in range(len_data, 90):\n",
    "            curr_x.append(np.zeros((224, 224, 3)))\n",
    "\n",
    "    curr_x = np.array(curr_x)\n",
    "\n",
    "    X_train.append(curr_x)\n",
    "    y_train.append(curr_y)\n",
    "\n",
    "for filename in test_files:\n",
    "    filename_int = int(filename.split('.mp4')[0])\n",
    "\n",
    "    if filename_int <= 115:\n",
    "        curr_y = 1\n",
    "        subdir_name = 'armflapping'\n",
    "    else:\n",
    "        curr_y = 0\n",
    "        subdir_name = 'control'\n",
    "\n",
    "    curr_x = []\n",
    "    for frame in os.listdir('../behavior_data/' + subdir_name + '/' + filename):\n",
    "\n",
    "        frame_num = int(frame.split('.')[0])\n",
    "        if frame_num > 90:\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread('../behavior_data/' + subdir_name + '/' + filename + '/' + frame)\n",
    "        try:\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        curr_x.append(image)\n",
    "\n",
    "    len_data = len(os.listdir('../behavior_data/' + subdir_name + '/' + filename))\n",
    "    if len_data < 90:\n",
    "        for abc in range(len_data, 90):\n",
    "            curr_x.append(np.zeros((224, 224, 3)))\n",
    "\n",
    "    curr_x = np.array(curr_x)\n",
    "\n",
    "    X_test.append(curr_x)\n",
    "    y_test.append(curr_y)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "                metrics = [['accuracy', tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]])\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    validation_data = (X_test, y_test),\n",
    "                    batch_size = 16,\n",
    "                epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74148800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-02 08:20:44.183294: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MBNet/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MBNet/assets\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9048dcd520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "# save the model \n",
    "model.save(\"MBNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f41d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1d425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
