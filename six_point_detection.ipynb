{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# We will try tracking the hands with just 6 landmarks, which will be a 6 x 3 x 2 = 36 length vector for each time step. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import cv2, os \n",
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import mediapipe as mp \n",
    "from PIL import Image as im \n",
    "import mediapipe as mp\n",
    "\n",
    "def hand_locations(frame, min_detection_confidence = 0.5, min_tracking_confidence = 0.5): \n",
    "    \"\"\"Only give 6 landmarks\"\"\"\n",
    "\n",
    "    hands = mp.solutions.hands.Hands(min_detection_confidence=min_detection_confidence, min_tracking_confidence=min_tracking_confidence) # MAKE SURE THIS IS ALL GOOD \n",
    "    results = hands.process(frame.astype('uint8'))\n",
    "    X_locations = [0] * 12\n",
    "    Y_locations = [0] * 12\n",
    "    Z_locations = [0] * 12\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        x = y = z = 0 \n",
    "        for hand, hand_landmark in enumerate(results.multi_hand_landmarks):\n",
    "            for i in range(0, 21):\n",
    "                if i not in [0, 4, 8, 12, 16, 20]: continue \n",
    "                landmark = hand_landmark.landmark[i]\n",
    "                X_locations[x] = landmark.x\n",
    "                Y_locations[y] = landmark.y \n",
    "                Z_locations[z] = landmark.z\n",
    "                x += 1; y += 1; z +=1; \n",
    "            \n",
    "    hands.close()\n",
    "    return np.concatenate([X_locations, Y_locations, Z_locations]) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\"\"\"read in all of the frames\"\"\"\n",
    "\n",
    "SECONDS_TO_DETECT = 2 # in seconds\n",
    "\n",
    "import os, cv2\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "\n",
    "ARMFLAPPING_VIDEOS = []\n",
    "CONTROL_VIDEOS = []\n",
    "ARMFLAPPING_FPS = [] # store the FPS of all armflapping videos \n",
    "CONTROL_FPS = [] # store the FPS of all control videos \n",
    "for video_name in tqdm(os.listdir('behavior_data/shorter_armflapping'), desc = \"armflapping_videos\"): \n",
    "    try: \n",
    "        cap = cv2.VideoCapture('behavior_data/shorter_armflapping/' + video_name)  \n",
    "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        if cap.get(cv2.CAP_PROP_FRAME_COUNT) / frame_rate < SECONDS_TO_DETECT: continue # too short! \n",
    "\n",
    "        FRAMES = [] # frames for this video \n",
    "\n",
    "        while cap.isOpened(): \n",
    "            _, image = cap.read() \n",
    "            if not _ : \n",
    "                break  \n",
    "            \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert to RGB. \n",
    "            FRAMES.append(image) \n",
    "        \n",
    "        ARMFLAPPING_VIDEOS.append(FRAMES)\n",
    "        ARMFLAPPING_FPS.append(frame_rate)\n",
    "    except Exception as e: \n",
    "        print(f\"failed on {video_name}\")\n",
    "\n",
    "for video_name in tqdm(os.listdir('behavior_data/shorter_control'), desc = \"control_videos\"): \n",
    "    try: \n",
    "        cap = cv2.VideoCapture('behavior_data/shorter_control/' + video_name)  \n",
    "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        if cap.get(cv2.CAP_PROP_FRAME_COUNT) / frame_rate < SECONDS_TO_DETECT: continue # too short! \n",
    "\n",
    "        FRAMES = [] # frames for this video \n",
    "\n",
    "        while cap.isOpened(): \n",
    "            _, image = cap.read() \n",
    "            if not _ : \n",
    "                break \n",
    "            \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert to RGB. \n",
    "            FRAMES.append(image)\n",
    "        \n",
    "        CONTROL_VIDEOS.append(FRAMES)\n",
    "        CONTROL_FPS.append(frame_rate)\n",
    "    except Exception as e: \n",
    "        print(f\"failed on {video_name}\")\n",
    "    \n",
    "len(ARMFLAPPING_VIDEOS), len(CONTROL_VIDEOS)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "armflapping_videos:  17%|█▋        | 18/108 [00:00<00:02, 33.45it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "failed on .DS_Store\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "armflapping_videos: 100%|██████████| 108/108 [00:04<00:00, 24.15it/s]\n",
      "control_videos:  23%|██▎       | 14/62 [00:00<00:02, 17.32it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "failed on .DS_Store\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "control_videos: 100%|██████████| 62/62 [00:02<00:00, 22.19it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(97, 50)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# get the locations of all of the videos \n",
    "\n",
    "ARMFLAPPING_LOCATIONS, CONTROL_LOCATIONS = [], []\n",
    "for FRAMES in tqdm(ARMFLAPPING_VIDEOS) :\n",
    "    locs = []\n",
    "    for frame in FRAMES: \n",
    "        locs.append(hand_locations(frame))\n",
    "    ARMFLAPPING_LOCATIONS.append(locs)\n",
    "\n",
    "for FRAMES in tqdm(CONTROL_VIDEOS):  \n",
    "    locs = []\n",
    "    \n",
    "    for frame in FRAMES: \n",
    "        locs.append(hand_locations(frame))\n",
    "    CONTROL_LOCATIONS.append(locs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 97/97 [03:03<00:00,  1.89s/it]\n",
      "100%|██████████| 50/50 [01:32<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "N = min([len(locs) for locs in [ARMFLAPPING_LOCATIONS, CONTROL_LOCATIONS]])\n",
    "ARMFLAPPING_LOCATIONS = ARMFLAPPING_LOCATIONS[:N]\n",
    "CONTROL_LOCATIONS = CONTROL_LOCATIONS[:N]\n",
    "ARMFLAPPING_LOCATIONS = np.array(ARMFLAPPING_LOCATIONS)\n",
    "CONTROL_LOCATIONS = np.array(CONTROL_LOCATIONS)\n",
    "\n",
    "# we can create a padding function in order to pad \n",
    "def pad(locations, maxlen = 90, padding = \"post\", truncating = \"post\"): \n",
    "    new_locations = locations.tolist() \n",
    "    empty_row = np.zeros((1, 36))\n",
    "    for i, video in tqdm(enumerate(new_locations)): \n",
    "        if len(video) < maxlen:  \n",
    "            for new_row in range(maxlen - len(video)): \n",
    "                if padding == \"post\": \n",
    "                    new_locations[i] = np.array(new_locations[i])\n",
    "                    new_locations[i] = np.concatenate([new_locations[i], empty_row])\n",
    "                if padding == \"pre\": \n",
    "                    new_locations[i] = np.array(new_locations[i])\n",
    "                    new_locations[i] = np.concatenate([empty_row, new_locations[i]])\n",
    "\n",
    "        if len(video) > maxlen: \n",
    "            if truncating == \"post\": \n",
    "                new_locations[i] = new_locations[i][:maxlen]\n",
    "            elif truncating == \"pre\": \n",
    "                new_locations[i] = new_locations[i][len(video) - maxlen : ]\n",
    "    return np.array(new_locations)\n",
    "\n",
    "padded_armflapping_locations = ARMFLAPPING_LOCATIONS\n",
    "padded_control_locations = CONTROL_LOCATIONS\n",
    "padded_armflapping_locations = pad(padded_armflapping_locations, maxlen = 90)\n",
    "padded_control_locations = pad(padded_control_locations, maxlen = 90)\n",
    "print(padded_control_locations.shape, padded_armflapping_locations.shape)\n",
    "assert padded_armflapping_locations.shape == padded_control_locations.shape "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:00, 22250.95it/s]\n",
      "50it [00:00, 11198.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50, 90, 36) (50, 90, 36)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(ARMFLAPPING_LOCATIONS, CONTROL_LOCATIONS): \n",
    "    ARMFLAPPING_LABELS = np.ones(ARMFLAPPING_LOCATIONS.shape[0])\n",
    "    CONTROL_LABELS = np.zeros(CONTROL_LOCATIONS.shape[0])\n",
    "    \n",
    "    # concatenate \n",
    "    data = np.concatenate([ARMFLAPPING_LOCATIONS, CONTROL_LOCATIONS])\n",
    "    labels = np.concatenate([ARMFLAPPING_LABELS, CONTROL_LABELS])\n",
    "    \n",
    "    return data, labels \n",
    "\n",
    "X, y = generate_data(padded_armflapping_locations, padded_control_locations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy\n",
    "import matplotlib.pyplot as plt \n",
    "def plot(history, show_pr = False, num = None): \n",
    "    \n",
    "    if num: \n",
    "        plt.plot(history.history['accuracy'], label = \"train_acc\")\n",
    "        plt.plot(history.history['val_accuracy'], label = \"val_acc\")\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history.history['loss'], label = \"train_loss\")\n",
    "        plt.plot(history.history['val_loss'], label = \"val_loss\")\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        if show_pr: \n",
    "            plt.plot(history.history[f'precision_{num}'], label = \"train_precision\")\n",
    "            plt.plot(history.history[f'val_precision_{num}'], label = \"val_precision\")\n",
    "            plt.title('model precision')\n",
    "            plt.ylabel('precision')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(history.history[f'recall_{num}'], label = \"train_recall\")\n",
    "            plt.plot(history.history[f'val_recall_{num}'], label = \"val_recall\")\n",
    "            plt.title('model recall')\n",
    "            plt.ylabel('recall')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    else: \n",
    "        plt.plot(history.history['accuracy'], label = \"train_acc\")\n",
    "        plt.plot(history.history['val_accuracy'], label = \"val_acc\")\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history.history['loss'], label = \"train_loss\")\n",
    "        plt.plot(history.history['val_loss'], label = \"val_loss\")\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        if show_pr: \n",
    "            plt.plot(history.history[f'precision'], label = \"train_precision\")\n",
    "            plt.plot(history.history[f'val_precision'], label = \"val_precision\")\n",
    "            plt.title('model precision')\n",
    "            plt.ylabel('precision')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(history.history[f'recall'], label = \"train_recall\")\n",
    "            plt.plot(history.history[f'val_recall'], label = \"val_recall\")\n",
    "            plt.title('model recall')\n",
    "            plt.ylabel('recall')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    # let's see whether it can detect me not doing anything \n",
    "\n",
    "def predict_on_video(model, path): \n",
    "    LOCATIONS = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    while cap.isOpened():\n",
    "        _, frame = cap.read()\n",
    "        if not _: break \n",
    "\n",
    "        LOCATIONS.append(hand_locations(frame))\n",
    "    LOCATIONS = pad(np.array([LOCATIONS]),maxlen=90)\n",
    "    return model.predict(LOCATIONS)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import random \n",
    "import tensorflow as tf \n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "def _shift(X):\n",
    "        \n",
    "        X = tf.Variable(X, dtype = tf.float32)\n",
    "        \n",
    "        X_locations = X[:, :12] \n",
    "        Y_locations = X[:,  12:24] \n",
    "        Z_locations = X[:, 24:]\n",
    "        \n",
    "        mask = tf.not_equal(Y_locations, 0) \n",
    "        nonzero_Y_locations = tf.boolean_mask(Y_locations, mask) # contains all nonzero elements of Y_locations \n",
    "    \n",
    "        maximum = tf.math.reduce_max(nonzero_Y_locations)\n",
    "        minimum = tf.math.reduce_min(nonzero_Y_locations)\n",
    "\n",
    "        can_move_up = 1 - maximum \n",
    "        can_move_down = minimum \n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "    \n",
    "        if tf.random.uniform((1,)) > 0.5: \n",
    "            move_up = tf.random.uniform((1,), 0, can_move_up)\n",
    "            X[:,  12:24].assign(X[:,  12:24] + mask * tf.ones_like(X[:,  12:24]) * move_up)\n",
    "        else: \n",
    "\n",
    "            move_down = tf.random.uniform((1,), 0, can_move_down)\n",
    "            X[:,  12:24].assign(X[:,  12:24] - mask * tf.ones_like(X[:,  12:24]) * move_down)\n",
    "\n",
    "        mask = tf.not_equal(X_locations, 0) \n",
    "        nonzero_X_locations = tf.boolean_mask(X_locations, mask) \n",
    "\n",
    "        maximum = tf.math.reduce_max(nonzero_X_locations)\n",
    "        minimum = tf.math.reduce_min(nonzero_X_locations)\n",
    "            \n",
    "        can_move_right = 1- maximum\n",
    "        can_move_left = minimum \n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        if tf.random.uniform((1,)) > 0.5: \n",
    "            # move right\n",
    "            move_right = tf.random.uniform((1,), 0, can_move_right)\n",
    "            X[:, :12].assign(X[:, :12] + mask * tf.ones_like(X[:, :12]) * move_right)\n",
    "\n",
    "        else: \n",
    "            # move left \n",
    "            move_left = tf.random.uniform((1,), 0, can_move_left)\n",
    "            X[:, :12].assign(X[:, :12] - mask * tf.ones_like(X[:, :12]) * move_left)\n",
    "\n",
    "        mask = tf.not_equal(Z_locations, 0) \n",
    "        nonzero_Z_locations = tf.boolean_mask(Z_locations, mask)\n",
    "\n",
    "        maximum = tf.math.reduce_max(nonzero_Z_locations)\n",
    "        minimum = tf.math.reduce_min(nonzero_Z_locations)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        can_move_far = 1 - maximum \n",
    "        can_move_close = minimum \n",
    "\n",
    "        if tf.random.uniform((1,)) > 0.5: \n",
    "            # move far\n",
    "            move_far = tf.random.uniform((1,), 0, can_move_far)\n",
    "            X[:, 24:].assign(X[:, 24:] + mask * tf.ones_like(X[:, 24:]) * move_far)\n",
    "        else: \n",
    "            # move close \n",
    "            move_close = tf.random.uniform((1,), 0, can_move_close)\n",
    "            X[:, 24:].assign(X[:, 24:] - mask * tf.ones_like(X[:, 24:]) * move_close)\n",
    "\n",
    "        return X\n",
    "\n",
    "class Augmenter(tf.keras.layers.Layer): \n",
    "    def __init__(self, rotation_range = None): \n",
    "        super().__init__()\n",
    "        self.trainable = False \n",
    "        self._trainable_weights = [] \n",
    "        self._non_trainable_weights = []\n",
    "        self.rotation_range = rotation_range \n",
    "    \n",
    "    def _rotate(self, X):  \n",
    "        \"\"\"\n",
    "        new_x = X * np.cos(theta * np.pi/180) + y * np.sin(theta * np.pi/180)\n",
    "        new_y = -X * np.sin(theta* np.pi/180) + y * np.cos(theta * np.pi/180)\n",
    "        \"\"\"\n",
    "        X = tf.Variable(X, dtype = tf.float32)\n",
    "\n",
    "        pi = 3.1415\n",
    "        rotate_by = tf.random.uniform((1,), -self.rotation_range, self.rotation_range)\n",
    "        X[:, :12].assign(X[:, :12] * tf.math.cos(rotate_by * pi/180) + X[:, 12:24] * tf.math.sin(rotate_by * pi/180))\n",
    "        X[:, 12:24].assign(X[:, 12:24] * tf.math.cos(rotate_by * pi/180) - X[:, :12] * tf.math.sin(rotate_by * pi/180))\n",
    "        return X \n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'vocab_size': 0,\n",
    "            'num_layers': 1,\n",
    "            'units': 0,\n",
    "            'd_model': 1,\n",
    "            'num_heads': 1,\n",
    "            'dropout': 0,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, X, training = True):\n",
    "        if training: \n",
    "            X =  tf.map_fn(_shift, X)\n",
    "            if self.rotation_range: \n",
    "                X = tf.map_fn(self._rotate, X)\n",
    "            return X\n",
    "        else: \n",
    "            return X \n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('val_accuracy') > 0.9):   \n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(0.9*100))   \n",
    "            self.model.stop_training = True  \n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for file in os.listdir('six_point_folds'): \n",
    "    with open(f\"six_point_folds/{file}\", 'rb') as f: \n",
    "        X_i, y_i = pickle.load(f)\n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def plot_roc_auroc(base_fpr, TPRs, FPRs, aurocs): \n",
    "    \n",
    "\n",
    "    for i, (tpr, fpr) in enumerate(zip(TPRs, FPRs)): \n",
    "        plt.plot(base_fpr, tpr, label = f\"fold {i + 1}\")\n",
    "\n",
    "    mean_tpr = np.mean(TPRs, axis=0)\n",
    "    plt.plot(base_fpr, mean_tpr, label = \"average of folds\")\n",
    "    \n",
    "    std_tpr = np.std(TPRs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=.3,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label = \"chance\")\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve across folds')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # plot the auroc curves \n",
    "    mean_auroc = sum(aurocs) / len(aurocs)\n",
    "    descriptions = [f\"fold {i + 1}\" for i in range(len(aurocs))] + [\"average fold\"]\n",
    "    aurocs.append(mean_auroc)\n",
    "    plt.bar(descriptions, aurocs, color = \"green\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Area Under Curve\")\n",
    "    plt.title(\"Area Under ROC Curve across folds\")\n",
    "    plt.show() \n",
    "\n",
    "    return mean_tpr, mean_auroc\n",
    "\n",
    "def plot_meta_roc_auroc(average_aurocs, average_tprs, base_fpr): \n",
    "    meta_avg_tpr = np.mean(average_tprs, axis = 0) \n",
    "    meta_avg_auroc = sum(average_aurocs) / len(average_aurocs)\n",
    "    \n",
    "    for i, average_tpr in enumerate(average_tprs): \n",
    "        plt.plot(base_fpr, average_tpr, label = f\"run {i + 1}\")\n",
    "    \n",
    "    plt.plot(base_fpr, meta_avg_tpr, label = \"average of runs\")\n",
    "    \n",
    "    std_tpr = np.std(average_tprs, axis=0)\n",
    "    tprs_upper = np.minimum(meta_avg_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(meta_avg_tpr - std_tpr, 0)\n",
    "    plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=.3, label=r'$\\pm$ 1 std. dev.')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label = \"chance\")\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Average ROC Curve across Runs (No Aug)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    descriptions = [f\"{i + 1}\" for i in range(len(average_aurocs))] + [\"avg\"]\n",
    "    average_aurocs.append(meta_avg_auroc)\n",
    "    plt.bar(descriptions, average_aurocs, color = \"green\")\n",
    "    plt.xlabel(\"Run Number\")\n",
    "    plt.ylabel(\"Area Under Curve\")\n",
    "    plt.title(\"Area Under ROC Curve across Runs (No Aug)\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm \n",
    "from scipy import interp\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "AVERAGE_TPRS, AVERAGE_AUROCS = [], [] \n",
    "def cross_validate(make_model, epochs = 50, callbacks=[]):\n",
    "    model = make_model()\n",
    "\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    FPRS, TPRS, AUROCS = [], [], []\n",
    "    for i in range(X.shape[0]): \n",
    "        model = make_model()\n",
    "\n",
    "        X_test, y_test = X[i], y[i]\n",
    "        X_train = np.concatenate([X_j for j, X_j in enumerate(X) if i != j])\n",
    "        y_train = np.concatenate([y_j for j, y_j in enumerate(y) if i != j])\n",
    "\n",
    "        try:\n",
    "            os.remove(\"best.h5\") \n",
    "        except Exception as e: \n",
    "            pass \n",
    "\n",
    "        # train \n",
    "        history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = epochs, callbacks = callbacks)\n",
    "        \n",
    "        try: \n",
    "            model.load_weights(\"best.h5\")\n",
    "        except Exception as e: \n",
    "            pass \n",
    "\n",
    "        # evaluate again \n",
    "        model.evaluate(X_test, y_test)\n",
    "        \n",
    "        # plot accuracy and loss \n",
    "        plot(history)\n",
    "\n",
    "        # get this information  \n",
    "        y_pred = model.predict(X_test).flatten()\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred) \n",
    "        FPRS.append(fpr)\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0 \n",
    "        TPRS.append(tpr)\n",
    "        AUROCS.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "        # evaluate on our own custom videos\n",
    "        for file in glob(\"*.mov\"):\n",
    "            print(f\"prediction for video {file} is {predict_on_video(model, file)}\")\n",
    "\n",
    "    mean_tpr, mean_auroc = plot_roc_auroc(base_fpr, TPRS, FPRS, AUROCS) \n",
    "    AVERAGE_TPRS.append(mean_tpr) \n",
    "    AVERAGE_AUROCS.append(mean_auroc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# we can also try using a Soft F1 Loss Metric \n",
    "\n",
    "import keras.backend as K \n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "import random \n",
    "def shuffle(X, y, seed = None):\n",
    "    if seed == None:  \n",
    "        seed = random.randrange(0, 100)\n",
    "        print(f\"using seed {seed}\")\n",
    "    np.random.seed(seed) \n",
    "    new_X = np.concatenate([X_i for X_i in X])\n",
    "    new_y = np.concatenate([y_i for y_i in y])\n",
    "    N = np.random.permutation(new_X.shape[0])\n",
    "    new_X = new_X[N]\n",
    "    new_y = new_y[N]\n",
    "    new_X = new_X.reshape(5, 20, 90, 36)\n",
    "    new_y = new_y.reshape(5, 20)\n",
    "    return new_X, new_y\n",
    "X, y = shuffle(X, y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using seed 3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "def make_model(): \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(16, return_sequences=False), \n",
    "        tf.keras.layers.Dropout(0.1), \n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid') \n",
    "    ]) \n",
    "\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.01), metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best.h5\", save_best_only=True, monitor = \"val_accuracy\")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", patience=10)\n",
    "cross_validate(make_model, epochs = 75, callbacks=[checkpoint, early_stopping]) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/75\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 0.6942 - accuracy: 0.5250 - precision_144: 0.7000 - recall_144: 0.1667 - val_loss: 0.7266 - val_accuracy: 0.3500 - val_precision_144: 0.3684 - val_recall_144: 0.8750\n",
      "Epoch 2/75\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.6225 - accuracy: 0.6125 - precision_144: 0.5821 - recall_144: 0.9286 - val_loss: 0.7628 - val_accuracy: 0.3500 - val_precision_144: 0.3684 - val_recall_144: 0.8750\n",
      "Epoch 3/75\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.5893 - accuracy: 0.6250 - precision_144: 0.5857 - recall_144: 0.9762 - val_loss: 0.7427 - val_accuracy: 0.4000 - val_precision_144: 0.3889 - val_recall_144: 0.8750\n",
      "Epoch 4/75\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.5614 - accuracy: 0.6500 - precision_144: 0.6094 - recall_144: 0.9286 - val_loss: 0.7458 - val_accuracy: 0.6000 - val_precision_144: 0.5000 - val_recall_144: 0.7500\n",
      "Epoch 5/75\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.5342 - accuracy: 0.7375 - precision_144: 0.7143 - recall_144: 0.8333 - val_loss: 0.7605 - val_accuracy: 0.6500 - val_precision_144: 0.5455 - val_recall_144: 0.7500\n",
      "Epoch 6/75\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.5544 - accuracy: 0.7375 - precision_144: 0.7143 - recall_144: 0.8333 - val_loss: 0.7313 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 7/75\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.5203 - accuracy: 0.7625 - precision_144: 0.7674 - recall_144: 0.7857 - val_loss: 0.7139 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 8/75\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.5171 - accuracy: 0.7750 - precision_144: 0.8000 - recall_144: 0.7619 - val_loss: 0.7114 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 9/75\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.5019 - accuracy: 0.7625 - precision_144: 0.7674 - recall_144: 0.7857 - val_loss: 0.7292 - val_accuracy: 0.7000 - val_precision_144: 0.6000 - val_recall_144: 0.7500\n",
      "Epoch 10/75\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.4937 - accuracy: 0.7625 - precision_144: 0.7556 - recall_144: 0.8095 - val_loss: 0.7288 - val_accuracy: 0.7000 - val_precision_144: 0.6000 - val_recall_144: 0.7500\n",
      "Epoch 11/75\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.4949 - accuracy: 0.7750 - precision_144: 0.7857 - recall_144: 0.7857 - val_loss: 0.7054 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 12/75\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.4798 - accuracy: 0.7750 - precision_144: 0.7857 - recall_144: 0.7857 - val_loss: 0.7078 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 13/75\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.4912 - accuracy: 0.7875 - precision_144: 0.8378 - recall_144: 0.7381 - val_loss: 0.7119 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 14/75\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.4651 - accuracy: 0.8000 - precision_144: 0.8250 - recall_144: 0.7857 - val_loss: 0.7286 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 15/75\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.4801 - accuracy: 0.7750 - precision_144: 0.7857 - recall_144: 0.7857 - val_loss: 0.7508 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 16/75\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.4672 - accuracy: 0.7875 - precision_144: 0.7907 - recall_144: 0.8095 - val_loss: 0.7404 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 17/75\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.4389 - accuracy: 0.8125 - precision_144: 0.8293 - recall_144: 0.8095 - val_loss: 0.7309 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 18/75\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.4477 - accuracy: 0.8125 - precision_144: 0.8293 - recall_144: 0.8095 - val_loss: 0.7551 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 19/75\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.4361 - accuracy: 0.8250 - precision_144: 0.8333 - recall_144: 0.8333 - val_loss: 0.7601 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 20/75\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.4307 - accuracy: 0.8000 - precision_144: 0.8250 - recall_144: 0.7857 - val_loss: 0.7649 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 21/75\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.4296 - accuracy: 0.8125 - precision_144: 0.8293 - recall_144: 0.8095 - val_loss: 0.7710 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 22/75\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.4178 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.7703 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 23/75\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.4259 - accuracy: 0.8250 - precision_144: 0.8500 - recall_144: 0.8095 - val_loss: 0.7709 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 24/75\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8250 - precision_144: 0.8500 - recall_144: 0.8095"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7fa6357f05e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/weakref.py\", line 345, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 [==============================] - 1s 259ms/step - loss: 0.4115 - accuracy: 0.8250 - precision_144: 0.8500 - recall_144: 0.8095 - val_loss: 0.7721 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 25/75\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.4055 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.7263 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 26/75\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.4257 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.7168 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 27/75\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.4123 - accuracy: 0.8250 - precision_144: 0.8500 - recall_144: 0.8095 - val_loss: 0.7810 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 28/75\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3961 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.8168 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 29/75\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.4048 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.8478 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 30/75\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.3872 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.8744 - val_accuracy: 0.6000 - val_precision_144: 0.5000 - val_recall_144: 0.6250\n",
      "Epoch 31/75\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3829 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.8490 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 32/75\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3800 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.8776 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 33/75\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.4048 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.9156 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 34/75\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.3702 - accuracy: 0.8500 - precision_144: 0.8571 - recall_144: 0.8571 - val_loss: 0.8890 - val_accuracy: 0.6000 - val_precision_144: 0.5000 - val_recall_144: 0.6250\n",
      "Epoch 35/75\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3775 - accuracy: 0.8375 - precision_144: 0.8372 - recall_144: 0.8571 - val_loss: 0.8723 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 36/75\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3718 - accuracy: 0.8500 - precision_144: 0.8571 - recall_144: 0.8571 - val_loss: 0.9745 - val_accuracy: 0.6000 - val_precision_144: 0.5000 - val_recall_144: 0.6250\n",
      "Epoch 37/75\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.3730 - accuracy: 0.8500 - precision_144: 0.8571 - recall_144: 0.8571 - val_loss: 0.8977 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 38/75\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.3613 - accuracy: 0.8500 - precision_144: 0.8750 - recall_144: 0.8333 - val_loss: 0.8852 - val_accuracy: 0.7000 - val_precision_144: 0.6250 - val_recall_144: 0.6250\n",
      "Epoch 39/75\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.3519 - accuracy: 0.8500 - precision_144: 0.8750 - recall_144: 0.8333 - val_loss: 0.9070 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 40/75\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.3552 - accuracy: 0.8500 - precision_144: 0.8571 - recall_144: 0.8571 - val_loss: 1.0047 - val_accuracy: 0.6000 - val_precision_144: 0.5000 - val_recall_144: 0.6250\n",
      "Epoch 41/75\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3660 - accuracy: 0.8375 - precision_144: 0.8537 - recall_144: 0.8333 - val_loss: 0.9120 - val_accuracy: 0.6500 - val_precision_144: 0.5556 - val_recall_144: 0.6250\n",
      "Epoch 42/75\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.3467 - accuracy: 0.8500 - precision_144: 0.8750 - recall_144: 0.8333 - val_loss: 0.9607 - val_accuracy: 0.6500 - val_precision_144: 0.5714 - val_recall_144: 0.5000\n",
      "Epoch 43/75\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# so the things that'll make the model do better \n",
    "# are actually quite quite simple. \n",
    "\n",
    "## so experiments kinda telling us the truth of the universe, whicih is that random seed is everything. I should also check the Experiments.ipynb notebook instead of being a dumabss. This"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ]
}